{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class DecisionTree:\n",
    "    column_names = []\n",
    "    decision_tree={}\n",
    "    \n",
    "    def fill_missing_values(self,train_data_frm):\n",
    "#         print(\"colll \", train_data_frm.columns)\n",
    "        for col_index in range(len(train_data_frm.columns)):\n",
    "            cur_col_name = self.column_names[col_index]\n",
    "#             print(\"cur_col_name \", cur_col_name)\n",
    "#             print(\"train_data_frm[cur_col_name] \", train_data_frm[cur_col_name])\n",
    "            if self.get_type(col_index):\n",
    "                cur_col_name = self.column_names[col_index]\n",
    "                train_data_frm[cur_col_name].fillna(train_data_frm[cur_col_name].mean(), inplace=True)\n",
    "            else:\n",
    "                cur_col_name = self.column_names[col_index]\n",
    "                train_data_frm[cur_col_name].fillna(train_data_frm[cur_col_name].mode()[0], inplace=True)\n",
    "        return train_data_frm\n",
    "    \n",
    "    def drop_columns(self,train_data_frm):\n",
    "        train_data_frm = train_data_frm.drop('Id', axis=1)\n",
    "        train_data_frm = train_data_frm.drop('Alley', axis=1)\n",
    "        train_data_frm = train_data_frm.drop('PoolQC', axis=1)\n",
    "        train_data_frm = train_data_frm.drop('Fence', axis=1)\n",
    "        train_data_frm = train_data_frm.drop('MiscFeature', axis=1)\n",
    "        return train_data_frm\n",
    "    \n",
    "    def prepare_data(self,train_data_frm):\n",
    "        train_data_frm = self.drop_columns(train_data_frm)\n",
    "        self.column_names = list(train_data_frm.columns)\n",
    "        train_data_frm = self.fill_missing_values(train_data_frm)\n",
    "        return train_data_frm\n",
    "    \n",
    "    def train_validation_split(self,data_frm,validation_data_size):\n",
    "        if isinstance(validation_data_size, float):\n",
    "            validation_data_size=round(validation_data_size * len(data_frm))\n",
    "\n",
    "        indices=data_frm.index.tolist()\n",
    "\n",
    "        valid_indices=random.sample(indices, validation_data_size)\n",
    "        valid_datafrm=data_frm.loc[valid_indices]\n",
    "\n",
    "        train_datafrm=data_frm.drop(valid_indices)\n",
    "\n",
    "        return train_datafrm , valid_datafrm\n",
    "    \n",
    "    \n",
    "    def check_pure(self,train_data):\n",
    "        num_rows , num_cols = train_data.shape\n",
    "        check_col = train_data[:,num_cols-1]\n",
    "        unique_values = np.unique(check_col)\n",
    "        if len(unique_values)==1:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_type(self,index):\n",
    "#         print(index)\n",
    "#         print(self.column_names)\n",
    "        col_name = self.column_names[index]\n",
    "        continous_feat =['YrSold','MoSold','MiscVal','PoolArea','ScreenPorch','3SsnPorch','EnclosedPorch','OpenPorchSF','WoodDeckSF','GarageArea','GarageCars','GarageYrBlt','Fireplaces','TotRmsAbvGrd','Kitchen','Bedroom','LotFrontage','LotArea','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath']\n",
    "        if col_name in continous_feat:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def cal_current_mean_square(self,num_of_rows_below_split, num_of_rows_above_split,mean_square_below_values,\n",
    "                            mean_square_above_values,num_of_rows):\n",
    "    \n",
    "        current_mean_square = (num_of_rows_below_split/num_of_rows)*mean_square_below_values + (num_of_rows_above_split/num_of_rows)*mean_square_above_values\n",
    "        return current_mean_square\n",
    "    \n",
    "    def cal_mean_square(self,splitted_data):\n",
    "    #     print(\"in cal_mean_square\")\n",
    "        num_of_rows, num_of_cols = splitted_data.shape\n",
    "        price_values = splitted_data[:,num_of_cols-1]\n",
    "        overall_mean = price_values.mean()\n",
    "    #     print(price_values)\n",
    "        mean_square = np.square(np.subtract(price_values,overall_mean)).mean()\n",
    "        return mean_square\n",
    "    \n",
    "    def get_best_split(self,column_wise_potential_splits, train_data):\n",
    "    #     print(\"in get_best_split\")\n",
    "        num_of_rows ,num_of_cols = train_data.shape\n",
    "        best_split_col = None\n",
    "        best_split_val = None\n",
    "        overall_mean_square = sys.maxsize\n",
    "    #     print(num_of_cols-1)\n",
    "        overall_mean = train_data[:,num_of_cols-1].mean()\n",
    "    #     print(overall_mean)\n",
    "        for col_index,split_list in column_wise_potential_splits.items():\n",
    "    #         print(col_index)\n",
    "            col_values = train_data[:,col_index]\n",
    "    #         print(column_names[col_index])\n",
    "            for split_val in split_list:\n",
    "                values_below_split_val = []\n",
    "                values_above_split_val = []\n",
    "                if self.get_type(col_index):\n",
    "                    values_below_split_val = train_data[col_values <= split_val]\n",
    "                    values_above_split_val = train_data[col_values > split_val]\n",
    "    #                 print(\"continous\")\n",
    "                else:\n",
    "                    values_below_split_val = train_data[col_values == split_val]\n",
    "                    values_above_split_val = train_data[col_values != split_val]\n",
    "    #                 print(\"cat\")\n",
    "\n",
    "                mean_square_below_values=0\n",
    "                if len(values_below_split_val)!=0:\n",
    "                    mean_square_below_values = self.cal_mean_square(values_below_split_val)\n",
    "\n",
    "                mean_square_above_values=0\n",
    "                if len(values_above_split_val)!=0:\n",
    "                    mean_square_above_values = self.cal_mean_square(values_above_split_val)\n",
    "\n",
    "                num_of_rows_below_split ,num_of_cols_below_split = values_below_split_val.shape\n",
    "                num_of_rows_above_split ,num_of_cols_above_split = values_above_split_val.shape\n",
    "                current_mean_square = self.cal_current_mean_square(num_of_rows_below_split, num_of_rows_above_split,\n",
    "                                                              mean_square_below_values, mean_square_above_values,\n",
    "                                                              num_of_rows)\n",
    "                if current_mean_square < overall_mean_square:\n",
    "                    overall_mean_square = current_mean_square\n",
    "                    best_split_col = col_index\n",
    "                    best_split_val = split_val\n",
    "    #         print(overall_mean_square)\n",
    "    #             print(\"below \",mean_square_below_values)\n",
    "    #             print(\"above \",mean_square_below_values)\n",
    "        return best_split_col, best_split_val\n",
    "\n",
    "\n",
    "    def get_column_wise_potential_splits(self,train_data):\n",
    "        column_wise_potential_splits = {}\n",
    "        num_of_rows , num_of_cols = train_data.shape\n",
    "    #     print(num_of_rows , num_of_cols)\n",
    "        for index in range(num_of_cols-1):\n",
    "\n",
    "                column_values = train_data[:,index]\n",
    "                column_unique_values = np.unique(column_values)\n",
    "\n",
    "                if(self.get_type(index)):\n",
    "                    li=[]\n",
    "                    for i in range(1,len(column_unique_values)):\n",
    "                        li.append(((column_unique_values[i-1])+(column_unique_values[i]))/2)\n",
    "                    column_wise_potential_splits[index]=li\n",
    "                else:\n",
    "                    column_wise_potential_splits[index] = column_unique_values.tolist()\n",
    "\n",
    "        return column_wise_potential_splits   \n",
    "\n",
    "    def decision_tree_algo(self,train_data, current_level=0, max_depth=4):\n",
    "        num_rows, num_cols = train_data.shape\n",
    "\n",
    "        if self.check_pure(train_data) or num_rows<=2 or current_level==max_depth:\n",
    "            return train_data[:,num_cols-1].mean()\n",
    "\n",
    "        else:\n",
    "            current_level+=1\n",
    "            column_wise_potential_splits = self.get_column_wise_potential_splits(train_data)\n",
    "            best_col , best_split_val = self.get_best_split(column_wise_potential_splits, train_data)\n",
    "    #         print(best_col, best_split_val)\n",
    "            col_values = train_data[:,best_col]\n",
    "            data_left_tree=[]\n",
    "            data_right_tree=[]\n",
    "            if self.get_type(best_col):\n",
    "                data_left_tree = train_data[col_values <= best_split_val]\n",
    "                data_right_tree = train_data[col_values > best_split_val]\n",
    "    #                 print(\"continous\")\n",
    "            else:\n",
    "                data_left_tree = train_data[col_values == best_split_val]\n",
    "                data_right_tree = train_data[col_values != best_split_val]\n",
    "    #                 print(\"cat\")\n",
    "\n",
    "            split_feature = self.column_names[best_col]\n",
    "            qu = \"{} {}\".format(best_col, best_split_val)\n",
    "            subtree = {qu: []}\n",
    "\n",
    "            left_tree = self.decision_tree_algo(data_left_tree, current_level, max_depth)\n",
    "            right_tree = self.decision_tree_algo(data_right_tree, current_level, max_depth)\n",
    "\n",
    "            if left_tree==right_tree:\n",
    "                subtree=left_tree\n",
    "            else:\n",
    "                subtree[qu].append(left_tree)\n",
    "                subtree[qu].append(right_tree)\n",
    "\n",
    "            return subtree\n",
    "        \n",
    "    def get_price_from_tree(self,test_sample,tree):\n",
    "        list_qu = list(tree.keys())\n",
    "        ques = list_qu[0]\n",
    "        split_index , split_value = ques.split(\" \")\n",
    "\n",
    "        predicted_price = None\n",
    "        if self.get_type(int(split_index)):\n",
    "#             print(\"in\")\n",
    "            if test_sample[int(split_index)] <= float(split_value):\n",
    "                predicted_price = tree[ques][0]\n",
    "            else:\n",
    "                predicted_price = tree[ques][1]\n",
    "        else:\n",
    "            if test_sample[int(split_index)] == split_value:\n",
    "                predicted_price = tree[ques][0]\n",
    "            else:\n",
    "                predicted_price = tree[ques][1]\n",
    "\n",
    "        if isinstance(predicted_price, dict):\n",
    "            return self.get_price_from_tree(test_sample,predicted_price)\n",
    "        else:\n",
    "            return predicted_price\n",
    "    \n",
    "    def get_predicted_price(self, test_data):\n",
    "        predicted_price=[]\n",
    "        for test_sample in test_data:\n",
    "            current_predicted_price = self.get_price_from_tree(test_sample,self.decision_tree)\n",
    "            predicted_price.append(current_predicted_price)\n",
    "        return predicted_price\n",
    "   \n",
    "    def check_validation(self, train_data_frm, validation_data_size):\n",
    "        train_data_frm , validation_data_frm = self.train_validation_split(train_data_frm, validation_data_size)\n",
    "        train_data = train_data_frm.values\n",
    "        self.decision_tree = self.decision_tree_algo(train_data, max_depth=3)\n",
    "        print(self.decision_tree)\n",
    "        \n",
    "        validation_data_labels = validation_data_frm.iloc[:,-1].to_frame().values.tolist()\n",
    "        validation_data_frm = validation_data_frm.drop([validation_data_frm.columns[-1]],  axis='columns')\n",
    "        validation_data = validation_data_frm.values\n",
    "        predicted_price = self.get_predicted_price(validation_data)\n",
    "        \n",
    "        print(mean_squared_error(validation_data_labels, predicted_price))\n",
    "        print(r2_score(validation_data_labels,predicted_price))\n",
    "        \n",
    "    \n",
    "    \n",
    "    def train(self,train_path):\n",
    "        train_data_frm = pd.read_csv(train_path)\n",
    "        # print(train_data_frm.info())\n",
    "        # print(train_data_frm.shape)\n",
    "        train_data_frm = self.prepare_data(train_data_frm)\n",
    "#         self.check_validation(train_data_frm, validation_data_size = 10)\n",
    "        # # print(train_data_frm.info())\n",
    "        # print(train_data_frm.shape)\n",
    "        # print(train_data_frm.info())\n",
    "        # train_data_frm.shape\n",
    "#         validation_data_size = 10;\n",
    "#         random.seed(0)\n",
    "        # train_data , valid_data = train_validation_split(train_data_frm, validation_data_size)\n",
    "        train_data = train_data_frm.values\n",
    "        self.decision_tree = self.decision_tree_algo(train_data, max_depth=5)\n",
    "        print(self.decision_tree)\n",
    "        \n",
    "    def predict(self,test_path):\n",
    "        test_data_frm = pd.read_csv(test_path)\n",
    "        test_data_frm = self.prepare_data(test_data_frm)\n",
    "        # test_data_frm.info()\n",
    "        test_data = test_data_frm.values\n",
    "        # test_data = test_data[:3]\n",
    "        predicted_price = self.get_predicted_price(test_data)\n",
    "        return predicted_price\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'59 2.5': [{'44 1477.5': [{'17 1985.5': [{'36 1007.5': [{'39 N': [84260.3953488372, 121263.49344978166]}, {'2 71.15515151515152': [129324.9, 152743.8775510204]}]}, {'44 1145.5': [{'3 15456.0': [146124.0, 84500.0]}, {'36 1239.0': [173999.6052631579, 194490.2]}]}]}, {'25 TA': [{'3 11725.5': [{'17 1965.5': [148812.14285714287, 178696.68421052632]}, {'54 1.5': [184778.7027027027, 254069.44444444444]}]}, {'41 1047.0': [{'13 1Fam': [202709.07407407407, 149937.5]}, {'32 846.5': [237703.68181818182, 275907.14285714284]}]}]}]}, {'44 2712.0': [{'44 1662.0': [{'36 1467.0': [{'18 1973.0': [115725.0, 191025.36363636365]}, {'65 44.5': [270685.6, 235823.07692307694]}]}, {'32 1267.5': [{'18 1990.0': [164000.0, 303437.49206349207]}, {'15 10': [472890.0, 362822.93333333335]}]}]}, {'49 4': [{'42 1692.5': [{'47 2.5': [431288.5, 540628.5]}, {'3 28647.5': [750000.0, 625000.0]}]}, {'2 110.0': [307500.0, 184750.0]}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "# import DecisionTree as dtree\n",
    "dtree_regressor = DecisionTree()\n",
    "dtree_regressor.train('/home/jyoti/Documents/SMAI/assign1/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('/home/jyoti/Documents/SMAI/assign1/q3/test.csv')\n",
    "# print(predictions)\n",
    "test_labels = list()\n",
    "with open('/home/jyoti/Documents/SMAI/assign1/q3/test_labels.csv') as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "# print(mean_squared_error(test_labels, predictions))\n",
    "# print(r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report on Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1539343732.5702562\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27814.559798322818\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7087227016170856\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(test_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
